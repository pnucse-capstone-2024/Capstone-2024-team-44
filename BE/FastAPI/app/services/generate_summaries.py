from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from app.settings import app_settings
import logging

logger = logging.getLogger(__name__)

async def validate_openai_api_key(api_key: str) -> bool:
    try:
        chatmodel = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.3,
            max_tokens=10,
            openai_api_key=api_key
        )
        
        prompt = (
            "This is a test prompt to validate the OpenAI API key. "
            "You can respond with just 'Hi'."
        )
        
        prompt_template = PromptTemplate(input_variables=["prompt"], template="{prompt}")
        formatted_prompt = prompt_template.format(prompt=prompt)

        # API í˜¸ì¶œ
        response = chatmodel.invoke(formatted_prompt)
        
        return True
    except Exception as e:
        return False

async def generate_log_summary(content: str):    
    prompt = (
        "### Persona ###\n"
        "You are an expert system log analyst. Summarize and detect anomalies in the following system logs.\n"
        "Focus only on essential information for problem-solving.\n"
        "\n"
        "### Writing Guidelines ###\n"
        "Your responses should be in Korean.\n"
        "Use icons or emojis (e.g., ğŸ“Š for summaries, â— for errors, âš ï¸ for warnings, â„¹ï¸ for info, ğŸš¨ for anomalies, ğŸ” for analysis required, ğŸ’¡ for recommended actions, and ğŸ”” for critical alerts) to clearly separate sections and highlight key points.\n"
        "Only list detected items. If fewer than three events or anomalies are detected, list only those present and avoid empty slots.\n"
        "Include 'None' if there are no events or anomalies to report.\n"
        "Ensure that all numerical values (e.g., total occurrences) are calculated precisely based on the input data provided. Do not assume or estimate values; use the actual data for calculations.\n"
        "Ensure all results and conclusions are directly based on the provided data patterns and metrics."
        "\n"
        "### Input Data ###\n"
        f"{content}\n"
        "\n"
        "### Log Summary ###\n"
        "Format the response in the following structure:\n"
        "\n"
        "ğŸ“Š [ì¼ë°˜ì ì¸ ìš”ì•½]\n"
        "- ì£¼ìš” ì´ë²¤íŠ¸\n"
        "   1. [Event 1]\n"
        "   2. [Event 2]\n"
        "   3. [Event 3]\n"
        "   ...(continue numbering as needed)\n"
        "- ë°œìƒ ë¹ˆë„\n"
        "   - â—ERROR: [number of ERRORs]\n"
        "   - âš ï¸ WARN: [number of WARNs]\n"
        "   - â„¹ï¸ INFO: [number of INFOs]\n"
        "\n"
        "ğŸš¨ [ì´ìƒ íƒì§€ ìš”ì•½]\n"
        "- íƒì§€ëœ ë¹„ì •ìƒ íŒ¨í„´\n"
        "   1. [Abnormal Pattern 1]: [Impact]\n"
        "   2. [Abnormal Pattern 2]: [Impact]\n"
        "   3. [Abnormal Pattern 3]: [Impact]\n"
        "   ...(continue numbering as needed)\n"
        "- ê¶Œì¥ ì¡°ì¹˜\n"
        "   1. [Actionable Recommendation 1]\n"
        "   2. [Actionable Recommendation 2]\n"
        "   3. [Actionable Recommendation 3]\n"
        "   ...(continue numbering as needed)\n"
        "\n"
        "ğŸ” [ê¸´ê¸‰ ì—¬ë¶€ ì²´í¬]\n"
        "- Immediate Risk: Respond with `true` if immediate action is needed for critical system risks like severe downtime or operational disruptions; otherwise, `false`.\n"
        "- [true/false]"
    )

    chatmodel = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.3,
        max_tokens=1200,
        openai_api_key=app_settings.OPENAI_API_KEY
    )
    
    prompt_template = PromptTemplate(input_variables=["prompt"], template="{prompt}")
    formatted_prompt = prompt_template.format(prompt=prompt)

    response = chatmodel.invoke(formatted_prompt)
    response_text = response.content  
    
    urgency_start_index = response_text.find("ğŸ” [ê¸´ê¸‰ ì—¬ë¶€ ì²´í¬]")
    
    if urgency_start_index != -1:
        log_summary = response_text[:urgency_start_index].strip()  
        is_urgent_line = response_text[urgency_start_index:].split('\n')[-1].strip()  
        is_urgent = "true" in is_urgent_line.lower()
    else:
        log_summary = response_text.strip()  
        is_urgent = False  

    return log_summary, is_urgent

async def generate_performance_summary(content: str):    
    prompt = (
        "### Persona ###\n"
        "You are an expert system performance analyst. Summarize and identify abnormal patterns in the following performance metrics.\n"
        "Focus on essential details for administrators to understand key events and anomalies. Only include critical and urgent recommendations.\n"
        "\n"
        "### Writing Guidelines ###\n"
        "Your responses should be in Korean.\n"
        "For abnormal patterns, focus on unusual spikes, sustained high usage, or significant deviations from typical values.\n"
        "Use icons or emojis (e.g., ğŸ“ˆ for summaries, ğŸ’» for CPU, ğŸ’½ for memory, â¬‡ï¸ for network receive, â¬†ï¸ for network send, âš ï¸ for anomalies, and ğŸ”§ for recommended actions) to clearly separate sections and highlight key points.\n"
        "Only list detected items. If fewer than three events or anomalies are detected, list only those present and avoid empty slots.\n"
        "When specifying 'maximum' values, ensure that the corresponding occurrence time is accurately extracted from the data. Avoid assumptions or approximations.\n"
        "Ensure that all numerical values (e.g., averages, maximums) are calculated precisely based on the input data provided. Do not assume or estimate values; use the actual data for calculations.\n"
        "Ensure all results and conclusions are directly based on the provided data patterns and metrics."
        "\n"
        "### Input Data ###\n"
        f"{content}\n"
        "\n"
        "### Performance Summary ###\n"
        "Format the response in the following structure:\n"
        "\n"
        "ğŸ“ˆ [ì„±ëŠ¥ ê°œìš”]"
        "   - ğŸ’» CPU\n"
        "     - í‰ê·  ì‚¬ìš©ëŸ‰: [í‰ê·  CPU ì‚¬ìš©ëŸ‰]%\n"
        "     - ìµœëŒ€ ì‚¬ìš©ëŸ‰: [ìµœëŒ€ CPU ì‚¬ìš©ëŸ‰]% (ë°œìƒ ì‹œê°„: [ìµœëŒ€ ì‹œê°„])\n"
        "   - ğŸ’½ ë©”ëª¨ë¦¬\n"
        "     - í‰ê·  ì‚¬ìš©ëŸ‰: [í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰] MB\n"
        "     - ìµœëŒ€ ì‚¬ìš©ëŸ‰: [ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰] MB (ë°œìƒ ì‹œê°„: [ìµœëŒ€ ì‹œê°„])\n"
        "   - â¬‡ï¸ ë„¤íŠ¸ì›Œí¬ ìˆ˜ì‹ \n"
        "     - í‰ê·  ìˆ˜ì‹ ëŸ‰: [í‰ê·  ìˆ˜ì‹ ëŸ‰] KB\n"
        "     - ìµœëŒ€ ìˆ˜ì‹ ëŸ‰: [ìµœëŒ€ ìˆ˜ì‹ ëŸ‰] KB (ë°œìƒ ì‹œê°„: [ìµœëŒ€ ì‹œê°„])\n"
        "   - â¬†ï¸ ë„¤íŠ¸ì›Œí¬ ì†¡ì‹ \n"
        "     - í‰ê·  ì†¡ì‹ ëŸ‰: [í‰ê·  ì†¡ì‹ ëŸ‰] KB\n"
        "     - ìµœëŒ€ ì†¡ì‹ ëŸ‰: [ìµœëŒ€ ì†¡ì‹ ëŸ‰] KB (ë°œìƒ ì‹œê°„: [ìµœëŒ€ ì‹œê°„])\n"
        "\n"
        "âš ï¸ [íƒì§€ëœ ë¹„ì •ìƒ íŒ¨í„´]\n"
        "   1. [Abnormal Pattern 1]: [Impact]\n"
        "   2. [Abnormal Pattern 2]: [Impact]\n"
        "   3. [Abnormal Pattern 3]: [Impact]\n"
        "   ...(continue numbering as needed)\n"
        "\n"
        "ğŸ”§ [ê¶Œì¥ ì¡°ì¹˜]\n"
        "   1. [Actionable Recommendation 1]\n"
        "   2. [Actionable Recommendation 2]\n"
        "   3. [Actionable Recommendation 3]\n"
        "   ...(continue numbering as needed)\n"
    )

    chatmodel = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.3,
        max_tokens=500,
        openai_api_key=app_settings.OPENAI_API_KEY
    )
    
    prompt_template = PromptTemplate(input_variables=["prompt"], template="{prompt}")
    formatted_prompt = prompt_template.format(prompt=prompt)

    response = chatmodel.invoke(formatted_prompt)
    performance_summary = response.content  

    return performance_summary

async def generate_daily_summary(content: str):    
    prompt = (
        "### Persona ###\n"
        "You are an expert system performance and application log analyst. Generate a daily key summary report based on application and performance logs.\n"
        "Focus on key events, abnormal patterns, and immediate actions required to resolve issues.\n"
        "### Writing Guidelines ###\n"
        "Your responses should be in Korean.\n"
        "Use icons (e.g., ğŸ” for the report, â— for errors, âš ï¸ for warnings, ğŸ“Š for performance overview, ğŸ”¥ for high utilization, ğŸ’» for CPU, ğŸ’½ for memory, â¬‡ï¸ for network receive, â¬†ï¸ for network send, ğŸš¨ for anomalies, and ğŸ”§ for recommended actions) to clearly separate sections and highlight key points.\n"
        "Only list detected items. If fewer than three events or anomalies are detected, list only those present and avoid empty slots.\n"
        "When specifying 'maximum' values, ensure that the corresponding occurrence time is accurately extracted from the data. Avoid assumptions or approximations.\n"
        "Ensure that all numerical values (e.g., total occurrences, averages, maximums) are calculated precisely based on the input data provided. Do not assume or estimate values; use the actual data for calculations.\n"
        "Ensure all results and conclusions are directly based on the provided data patterns and metrics."
        "\n"
        "### Input Data ###\n"
        f"{content}\n"
        "\n"
        "### Daily Key Summary Report ###\n"
        "Format the response in the following structure:\n"
        "\n"
        "ğŸ” ì¼ì¼ í•µì‹¬ ìš”ì•½ ë¦¬í¬íŠ¸\n"
        "\n"
        "âš ï¸ [ì£¼ìš” ê²½ê³  ë° ì˜¤ë¥˜]\n"
        "  - ê²½ê³ /ì˜¤ë¥˜ í•­ëª©ë“¤\n"
        "    1. â—[Critical warning or error 1]: [Impact]\n"
        "       - ì›ì¸: [Potential root cause]\n"
        "    2. â—[Critical warning or error 2]: [Impact]\n"
        "       - ì›ì¸: [Potential root cause]\n"
        "    3. â—[Critical warning or error 3]: [Impact]\n"
        "       - ì›ì¸: [Potential root cause]\n"
        "    ...(continue numbering as needed)\n"
        "\n"
        "  - ë°œìƒ ë¹ˆë„\n"
        "    - ERROR: [Total number of ERRORs]\n"
        "    - WARN: [Total number of WARNs]\n"
        "\n"
        "ğŸ“Š [ì‹œìŠ¤í…œ ì„±ëŠ¥ ê°œìš”]\n"
        "  - ğŸ’» CPU: í‰ê·  [í‰ê·  CPU ì‚¬ìš©ëŸ‰]%, ìµœëŒ€ [ìµœëŒ€ CPU ì‚¬ìš©ëŸ‰]% (ë°œìƒ ì‹œê°„: [ìµœëŒ€ CPU ì‚¬ìš©ëŸ‰ ë°œìƒ ì‹œê°„])\n"
        "  - ğŸ’½ ë©”ëª¨ë¦¬: í‰ê·  [í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰] MB, ìµœëŒ€ [ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰] MB (ë°œìƒ ì‹œê°„: [ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°œìƒ ì‹œê°„])\n"
        "  - â¬‡ï¸ ë„¤íŠ¸ì›Œí¬ ìˆ˜ì‹ : í‰ê·  [í‰ê·  ìˆ˜ì‹ ëŸ‰] MB, ìµœëŒ€ [ìµœëŒ€ ìˆ˜ì‹ ëŸ‰] MB (ë°œìƒ ì‹œê°„: [ìµœëŒ€ ìˆ˜ì‹ ëŸ‰ ë°œìƒ ì‹œê°„])\n"
        "  - â¬†ï¸ ë„¤íŠ¸ì›Œí¬ ì†¡ì‹ : í‰ê·  [í‰ê·  ì†¡ì‹ ëŸ‰] MB, ìµœëŒ€ [ìµœëŒ€ ì†¡ì‹ ëŸ‰] MB (ë°œìƒ ì‹œê°„: [ìµœëŒ€ ì†¡ì‹ ëŸ‰ ë°œìƒ ì‹œê°„])\n"
        "\n"
        "ğŸš¨ [íƒì§€ëœ ë¹„ì •ìƒ íŒ¨í„´]\n"
        "  - [Abnormal Pattern 1]: [Impact]\n"
        "  - [Abnormal Pattern 2]: [Impact]\n"
        "  - [Abnormal Pattern 3]: [Impact]\n"
        "   ...(continue numbering as needed)\n"
        "\n"
        "ğŸ”§ [ê¸´ê¸‰ ê¶Œì¥ ì¡°ì¹˜]\n"
        "  - [Actionable Recommendation 1]\n"
        "  - [Actionable Recommendation 2]\n"
        "  - [Actionable Recommendation 3]\n"
        "   ...(continue numbering as needed)\n"
        "\n"
    )

    chatmodel = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.3,
        max_tokens=1200,
        openai_api_key=app_settings.OPENAI_API_KEY
    )
    
    prompt_template = PromptTemplate(input_variables=["prompt"], template="{prompt}")
    formatted_prompt = prompt_template.format(prompt=prompt)

    response = chatmodel.invoke(formatted_prompt)
    daily_summary = response.content  

    return daily_summary

async def generate_trend_summary(content: str):    
    prompt = (
        "### Persona ###\n"
        "You are an expert system performance and application log analyst. Generate a weekly long-term trend analysis report based on daily key summaries.\n"
        "The report should emphasize system performance trends, error/warning patterns, abnormal patterns, and provide predictions based on the analyzed data.\n"
        "Focus on identifying trends and drawing insights from weekly data.\n"
        "\n"
        "### Writing Guidelines ###\n"
        "Your responses should be in Korean.\n"
        "Use icons to organize sections (e.g., ğŸ“Š for report title, â— for errors, âš ï¸ for warnings, ğŸ“ˆ for increasing trends, ğŸ“‰ for decreasing trends, ğŸ’» for CPU, ğŸ’½ for memory, â¬‡ï¸ for network receive, â¬†ï¸ for network send, ğŸš¨ for abnormal patterns, ğŸ” for insights, ğŸ”® for predictions, and ğŸ”§ for recommended actions).\n"
        "Only list detected items. If fewer than three events or anomalies are detected, list only those present and avoid empty slots.\n"
        "When specifying 'maximum' values, ensure that the corresponding occurrence time is accurately extracted from the data. Avoid assumptions or approximations.\n"
        "Ensure that all numerical values (e.g., total occurrences, averages, maximums, trends) are calculated precisely based on the input data provided. Do not assume or estimate values; use the actual data for calculations.\n"
        "Ensure all results and conclusions are directly based on the provided data patterns and metrics."
        "### Input Data ###\n"
        f"{content}\n"
        "\n"
        "### Weekly Long-Term Trend Analysis Report ###\n"
        "Format the response in the following structure:\n"
        "\n"
        "ğŸ“Š ì£¼ê°„ ì¥ê¸° íŠ¸ë Œë“œ ë¶„ì„ ë¦¬í¬íŠ¸\n"
        "\n"
        "â— [ê²½ê³  ë° ì˜¤ë¥˜ íŠ¸ë Œë“œ ë¶„ì„]\n"
        "   - ì£¼ìš” ê²½ê³  ë° ì˜¤ë¥˜ ë°œìƒ ì¶”ì„¸\n"
        "     - ERROR ë°œìƒ ì´ íšŸìˆ˜: [ì´ íšŸìˆ˜]íšŒ\n"
        "     - WARN ë°œìƒ ì´ íšŸìˆ˜: [ì´ íšŸìˆ˜]íšŒ\n"
        "     - ì£¼ê°„ ë°œìƒ ì¶”ì´: [ìš”ì¼ë³„ë¡œ ë°ì´í„° ë‚˜ì—´]\n"
        "       - ì›”ìš”ì¼: ERROR [íšŸìˆ˜], WARN [íšŸìˆ˜]\n"
        "       - í™”ìš”ì¼: ERROR [íšŸìˆ˜], WARN [íšŸìˆ˜]\n"
        "       - â€¦ (ê° ìš”ì¼ë³„ ìƒì„¸ ë°ì´í„°)\n"   
        "     - ì¦ê°€/ê°ì†Œ íŠ¸ë Œë“œ: ì§€ë‚œì£¼ ëŒ€ë¹„ [ì¦ê°€ìœ¨/ê°ì†Œìœ¨]%\n"
        "\n"
        "   - ğŸ“‹ ì£¼ìš” ë¬¸ì œ ìœ í˜•\n"
        "     1. [Error Type 1] - [íšŸìˆ˜]íšŒ ë°œìƒ (ì£¼ë¡œ [ì‹œê°„ëŒ€]ì— ì§‘ì¤‘)\n"
        "        - ì›ì¸: [ë¬¸ì œì˜ ì£¼ìš” ì›ì¸]\n"
        "        - ì˜í–¥: [ì´ ë¬¸ì œë¡œ ì¸í•œ ì‹œìŠ¤í…œ ë˜ëŠ” ì„œë¹„ìŠ¤ì˜ ì˜í–¥]\n"
        "        - í•´ê²° ì¡°ì¹˜: [ê¶Œì¥ë˜ëŠ” í•´ê²° ë°©ë²•]\n"
        "     2. [Error Type 2] - [íšŸìˆ˜]íšŒ ë°œìƒ (ì£¼ë¡œ [ì‹œê°„ëŒ€]ì— ì§‘ì¤‘)\n"
        "     3. [Error Type 3] - [íšŸìˆ˜]íšŒ ë°œìƒ (ì£¼ë¡œ [ì‹œê°„ëŒ€]ì— ì§‘ì¤‘)\n"
        "     ...(continue numbering as needed)\n"
        "\n"
        "   - ğŸ” ì£¼ìš” ì¸ì‚¬ì´íŠ¸\n"
        "     - ì›ì¸ ë¶„ì„: [ì£¼ìš” ì›ì¸ A]\n"
        "        - ê´€ë ¨ ì§€í‘œ: [ê´€ë ¨ëœ ì„±ëŠ¥ ì§€í‘œ] (ì˜ˆ: CPU, ë©”ëª¨ë¦¬ ë“±)\n"
        "        - ì—°ê´€ ë¬¸ì œ: [ì´ ì›ì¸ê³¼ ì—°ê´€ëœ ë‹¤ë¥¸ ë¬¸ì œ ë˜ëŠ” ê²½ê³ ]\n"
        "     ...(include additional insights as needed)\n"
        "\n"
        "ğŸ“ˆ [ì„±ëŠ¥ ì§€í‘œ íŠ¸ë Œë“œ ë¶„ì„]\n"
        "   - ğŸ’» CPU ì‚¬ìš©ëŸ‰ íŠ¸ë Œë“œ\n"
        "     - ì£¼ê°„ í‰ê· : [í‰ê·  CPU ì‚¬ìš©ëŸ‰]%\n"
        "     - ìµœëŒ€ ì‚¬ìš©ëŸ‰: [ìµœëŒ€ ì‚¬ìš©ëŸ‰]% (ì‹œê°„: [ìµœëŒ€ ì‚¬ìš© ì‹œê°„])\n"
        "     - ì¼ë³„ CPU ì‚¬ìš©ëŸ‰ ì¶”ì´: [ìš”ì¼ë³„ ë°ì´í„°]\n"
        "\n"
        "   - ğŸ’½ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ íŠ¸ë Œë“œ\n"
        "     - ì£¼ê°„ í‰ê· : [í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰] MB\n"
        "     - ìµœëŒ€ ì‚¬ìš©ëŸ‰: [ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰] MB (ì‹œê°„: [ìµœëŒ€ ì‚¬ìš© ì‹œê°„])\n"
        "     - ì¼ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì´: [ìš”ì¼ë³„ ë°ì´í„°]\n"
        "\n"
        "   - ğŸ“‰ ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ íŠ¸ë Œë“œ\n"
        "     - ìˆ˜ì‹ ëŸ‰: í‰ê·  [í‰ê·  ìˆ˜ì‹ ëŸ‰] MB, ìµœëŒ€ [ìµœëŒ€ ìˆ˜ì‹ ëŸ‰] MB (ë°œìƒ ì‹œê°„: [ìµœëŒ€ ìˆ˜ì‹ ëŸ‰ ì‹œê°„])\n"
        "     - ì†¡ì‹ ëŸ‰: í‰ê·  [í‰ê·  ì†¡ì‹ ëŸ‰] MB, ìµœëŒ€ [ìµœëŒ€ ì†¡ì‹ ëŸ‰] MB (ë°œìƒ ì‹œê°„: [ìµœëŒ€ ì†¡ì‹ ëŸ‰ ì‹œê°„])\n"
        "     - ì¼ë³„ ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ì¶”ì´:\n"
        "        - ìˆ˜ì‹ ëŸ‰: ì›”ìš”ì¼ [ìˆ˜ì‹ ëŸ‰] MB, í™”ìš”ì¼ [ìˆ˜ì‹ ëŸ‰] MB, â€¦\n"
        "        - ì†¡ì‹ ëŸ‰: ì›”ìš”ì¼ [ì†¡ì‹ ëŸ‰] MB, í™”ìš”ì¼ [ì†¡ì‹ ëŸ‰] MB, â€¦\n"
        "     - ì¦ê°€/ê°ì†Œ ë¹„ìœ¨: ë„¤íŠ¸ì›Œí¬ ìˆ˜ì‹  ë° ì†¡ì‹ ëŸ‰ì˜ ì£¼ê°„ ë³€í™”ìœ¨ - [ì¦ê°€ìœ¨/ê°ì†Œìœ¨]%"
        "\n"
        "ğŸš¨ [ë¹„ì •ìƒ íŒ¨í„´ ì¥ê¸° ë¶„ì„]\n"
        "   - [Abnormal Pattern 1]\n"
        "     - ë°œìƒ íšŸìˆ˜: [íšŸìˆ˜]" 
        "     - ë°œìƒ ì‹œê°„ëŒ€: [ì‹œê°„ ë²”ìœ„]\n"
        "     - ì—°ê´€ ì„±ëŠ¥ ì§€í‘œ: [ì—°ê´€ëœ ì„±ëŠ¥ ì§€í‘œ]\n"
        "   - [Abnormal Pattern 2]\n"
        "   - [Abnormal Pattern 3]\n"
        "     ...(continue numbering as needed)\n"
        "\n"
        "ğŸ“Š [í–¥í›„ ì˜ˆì¸¡ ë° ê¶Œì¥ ì¡°ì¹˜]\n"
        "   - ğŸ”® ì˜ˆì¸¡\n"
        "     1. [Actionable Recommendation 1]\n"
        "       - ì˜ˆìƒ ë¬¸ì œ: [ì˜ˆìƒë˜ëŠ” ë¬¸ì œì˜ ì„¤ëª…]\n"
        "       - ë°œìƒ ê°€ëŠ¥ì„±: [ë°œìƒ ê°€ëŠ¥ì„± ìˆ˜ì¤€] (ë‚®ìŒ/ì¤‘ê°„/ë†’ìŒ)\n"
        "       - ì˜ˆì¸¡ ê·¼ê±°: [ì£¼ìš” ì˜ˆì¸¡ ê·¼ê±° ë°ì´í„° ë˜ëŠ” ë¶„ì„ ìš”ì•½]\n"
        "       - ì˜ˆìƒ ì˜í–¥: [ë¬¸ì œê°€ ì‹œìŠ¤í…œ ë˜ëŠ” ì„œë¹„ìŠ¤ì— ë¯¸ì¹  ìˆ˜ ìˆëŠ” ì˜ˆìƒ ì˜í–¥]\n"
        "     2. [Actionable Recommendation 2]\n"
        "     3. [Actionable Recommendation 3]\n"
        "     ...(continue numbering as needed)\n"
        "\n"
        "   - ğŸ”§ ê¶Œì¥ ì¡°ì¹˜\n"
        "     1. [Actionable Recommendation 1]\n"
        "     2. [Actionable Recommendation 2]\n"
        "     3. [Actionable Recommendation 3]\n"        
        "     ...(continue numbering as needed)\n"
        "\n"
    )

    chatmodel = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.3,
        max_tokens=2000,
        openai_api_key=app_settings.OPENAI_API_KEY
    )
    
    prompt_template = PromptTemplate(input_variables=["prompt"], template="{prompt}")
    formatted_prompt = prompt_template.format(prompt=prompt)

    response = chatmodel.invoke(formatted_prompt)
    trend_summary = response.content  

    return trend_summary

async def generate_recommend(content: str):    
    prompt = (
        "### Persona ###\n"
        "You are an expert system performance analyst. Your task is to provide concise, actionable recommendations based on application logs and performance data from the past 6 hours.\n"
        "Focus on key performance issues and suggest immediate actions.\n"
        "### Writing Guidelines ###\n"
        "Your responses should be in Korean.\n"
        "Use icons to clearly organize recommendations and emphasize the type of action (e.g., ğŸ”§ for maintenance actions, ğŸš€ for optimization actions, âš ï¸ for urgent actions).\n"
        "Provide a list of brief, clear recommendations, starting each item with a dash (-). Include multiple items under each type if needed, and avoid empty slots.\n"
        "List only the most critical actions needed and avoid unnecessary details.\n"
        "Ensure all results and conclusions are directly based on the provided data patterns and metrics."
        "\n"
        "### Input Data ###\n"
        f"{content}\n"
        "\n"
        "### Recommendations ###\n"
        "Format the response as a list of brief, clear recommendations based on the input data:\n"
        "\n"
        "- âš ï¸ [Immediate action for critical issue 1]\n"
        "- âš ï¸ [Immediate action for critical issue 2]\n"
        "- ğŸ”§ [Maintenance action recommendation 1]\n"
        "- ğŸ”§ [Maintenance action recommendation 2]\n"
        "- ğŸš€ [Optimization action recommendation 1]\n"
        "- ğŸš€ [Optimization action recommendation 2]\n"
        "   ...(continue listing as needed for each type)\n"
        "\n"
    )

    chatmodel = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.3,
        max_tokens=750,
        openai_api_key=app_settings.OPENAI_API_KEY
    )
    
    prompt_template = PromptTemplate(input_variables=["prompt"], template="{prompt}")
    formatted_prompt = prompt_template.format(prompt=prompt)

    response = chatmodel.invoke(formatted_prompt)
    recommend = response.content  

    return recommend

async def generate_hourly_summary(content: str):    
    prompt = (
        "### Persona ###\n"
        "You are an expert system log and performance analyst. Analyze the logs and provide concise, one-line summaries focusing on critical issues or performance problems from the past hour.\n"
        "Only include urgent information that requires immediate attention. Ignore minor issues that do not significantly impact system performance.\n"
        "### Writing Guidelines ###\n"
        "Your responses should be in Korean.\n"
        "Focus on critical errors, performance issues, or warnings that require immediate action. Each summary should include the event time, criticality level, a brief issue description, and a recommended action (if needed).\n"
        "Use the following icons to indicate priority: â— for Critical, âš ï¸ for Warning, â„¹ï¸ for Info. Structure each summary as:\n  - [Criticality] [Event Time]: [Issue Description]. [Recommended Action]\n"
        "When specifying 'maximum' values, ensure that the corresponding occurrence time is accurately extracted from the data. Avoid assumptions or approximations.\n"
        "Ensure all results and conclusions are directly based on the provided data patterns and metrics."
        "\n"
        "### Log and Performance Data ###\n"
        f"{content}\n"
        "\n"
        "### One-Line Summaries ###\n"
        "Summarize the following logs, listing only critical items:\n"
        "\n"
        "1. â— [Event Time]: [Critical Issue Description]. [Immediate Action]\n"
        "2. âš ï¸ [Event Time]: [Warning Description]. [Suggested Action]\n"
        "3. â„¹ï¸ [Event Time]: [Informational Description]. [Recommended Action]\n"
        "   ...(continue as needed for all high-priority issues)\n"
        "\n"
    )

    chatmodel = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.3,
        max_tokens=750,
        openai_api_key=app_settings.OPENAI_API_KEY
    )
    

    prompt_template = PromptTemplate(input_variables=["prompt"], template="{prompt}")
    formatted_prompt = prompt_template.format(prompt=prompt)

    response = chatmodel.invoke(formatted_prompt)
    hourly_summary = response.content

    return hourly_summary